{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e95e3b-bbe2-4fff-9039-350b20b3d523",
   "metadata": {},
   "source": [
    "### 1. How would you load a CSV dataset using Pandas in Python? Provide a step-by-step code example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110338e8-fd7a-4fe6-acc6-f131673b8da8",
   "metadata": {},
   "source": [
    "#### Need to follow below steps to load a csv file to the pandas data frame\n",
    "\n",
    "1. Import the Pandas Library\n",
    "  * Need to import the Pandas library.\n",
    "  * you can install it using pip install pandas on the jupyter notebook cell\n",
    "\n",
    "3. Loading the CSV File\n",
    "  * Need to use the pd.read_csv() function to load the CSV file into a Pandas DataFrame.\n",
    "\n",
    "4. Visualise the Data\n",
    "  * After loading the data, you can print/visualise it by printing the first few rows or checking its structure by using different methods\n",
    "  \n",
    "Below are the methods.\n",
    "* print() : This method will be used to print all the rows\n",
    "* head() : This method will be uses to return first 5 rows of the dataframe\n",
    "* tail() : This method will used to print the last 5 rows of the dataframe\n",
    "* info() : This method will be used to get the summary of the DataFrame, including the number of non-null entries, data types of each column, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8c6ce58e-41ba-4903-9ec1-0c7cb8cea96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows\n",
      "--------------\n",
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "\n",
      "\n",
      "Last few rows\n",
      "--------------\n",
      "     total_bill   tip     sex smoker   day    time  size\n",
      "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
      "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
      "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
      "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
      "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
      "\n",
      "\n",
      "Info for the dataframe\n",
      "--------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  244 non-null    float64\n",
      " 1   tip         244 non-null    float64\n",
      " 2   sex         244 non-null    object \n",
      " 3   smoker      244 non-null    object \n",
      " 4   day         244 non-null    object \n",
      " 5   time        244 non-null    object \n",
      " 6   size        244 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 13.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1. Import the Pandas library\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Load the data.csv file\n",
    "df = pd.read_csv('tips.csv')\n",
    "\n",
    "# 3. Visualise the data\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows\")\n",
    "print(\"--------------\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the last few rows of the DataFrame\n",
    "print(\"\\n\")\n",
    "print(\"Last few rows\")\n",
    "print(\"--------------\")\n",
    "print(df.tail())\n",
    "\n",
    "#  Display the DataFrame's structure\n",
    "print(\"\\n\")\n",
    "print(\"Info for the dataframe\")\n",
    "print(\"--------------\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66525c-22c5-4147-bae4-f48a0912e0b6",
   "metadata": {},
   "source": [
    "### 2. Explain the role and importance of exploratory data analysis in the context of data preprocessing. \n",
    "### Give examples of techniques used in EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9239d82-1052-4e6a-9e05-d9a257b58217",
   "metadata": {},
   "source": [
    "1. Overview of Exploratory Data Analysis\n",
    "In the vast realm of data science and analytics, understanding and making sense of data is crucial. Before delving into sophisticated modeling or forecasting, it's pivotal to grasp the basic nature of the data we're dealing with. This foundational stage of analysis is called Exploratory Data Analysis, often abbreviated as EDA.\n",
    "\n",
    "EDA is the initial step in your data analysis process. Here, the focus is on understanding the patterns, spotting anomalies, testing a hypothesis, or checking assumptions related to a specific dataset. It's about being a detective, exploring the data to uncover its secrets and nuances. Often, it is during this process that the data speaks, revealing its essential stories and potentially guiding subsequent analysis or modeling.\n",
    "Various graphical representations, such as histograms, box plots, scatter plots, and more, aid in this exploration. Besides visual methods, EDA also involves statistical methods. For instance, understanding the distribution of a dataset, its central tendencies, or variance provides a comprehensive view of the data.\n",
    "\n",
    "2. Roles and importance of Exploratory Data Analysis\n",
    "\n",
    "*  Visualisation Tool:\n",
    "EDA employs a variety of visualization techniques to provide a clear view of the data. Visual methods are an intuitive way to understand the intricacies of the dataset and help in revealing hidden patterns, relationships, or anomalies.\n",
    "\n",
    "Histograms: Show the distribution of a single continuous variable.\n",
    "To visualize the distribution of age.\n",
    "Example: \n",
    "``` python\n",
    "sns.histplot(df['age']) \n",
    "```\n",
    "\n",
    "Boxplots: Used to detect outliers and understand the spread of data.\n",
    "Can show age distribution across different sex categories.\n",
    "Example:\n",
    "``` python\n",
    "sns.boxplot(x='sex', y='age', data=df)\n",
    "``` \n",
    "\n",
    "Scatter plots: Help in understanding relationships between two continuous variables.\n",
    "can reveal correlations between height and weight.\n",
    "Example: \n",
    "``` python\n",
    "sns.scatterplot(x='height', y='weight', data=df) \n",
    "```\n",
    "\n",
    "Pairplots: Show relationships between multiple features.\n",
    "plots pairwise relationships for all numeric features.\n",
    "Example: \n",
    "``` python\n",
    "sns.pairplot(df) \n",
    "```\n",
    "\n",
    "\n",
    "* Statistical Analysis:\n",
    "Description: Beyond visuals, EDA delves into statistical measures to quantify the characteristics of the dataset. These metrics provide a foundational understanding of the data's central tendencies, spread, and relationships.\n",
    "\n",
    "Example: describe() function in Pandas provides summary statistics for each numeric column\n",
    "\n",
    "``` python\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "* Handling Missing Data:\n",
    "Description: During EDA, it's crucial to detect and manage missing or null values. Missing data can skew results, reduce the statistical power of tests, and lead to biased estimates. EDA provides methods to either impute these values or make informed decisions about removing them.\n",
    "\n",
    "Filling Missing Data:Â¶\n",
    "The missing values can be replaced by meaningful data, such as .\n",
    "\n",
    "Mean\n",
    "Median\n",
    "Mode\n",
    "\n",
    "Other Methods\n",
    "Forward filling\n",
    "Backward filling\n",
    "Predictive modeling\n",
    "\n",
    "``` python\n",
    "# Fill missing values in column 'Age' with the mean of the column\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "```\n",
    "``` python\n",
    "# Fill missing values in the entire DataFrame with 0\n",
    "df.fillna(0, inplace=True)\n",
    "```\n",
    "``` python\n",
    "#Forward fill missing values\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "```\n",
    "``` python\n",
    "#Backward fill missing values\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "```\n",
    "\n",
    "* Identifying Outliers:\n",
    "Description: Outliers are data points that significantly deviate from the other observations. While some outliers are genuine and provide valuable information, others might be due to errors and can distort analysis results. EDA aids in spotting and, if necessary, addressing these outliers.\n",
    "\n",
    "Example: Boxplots and scatter plots can help spot outliers in continuous variables.\n",
    "\n",
    "* Correlation Analysis:\n",
    "Description: Understanding how different variables relate to each other is essential. Correlation analysis in EDA assesses the linear relationship between two quantitative variables, helping in feature selection and understanding multicollinearity.\n",
    "\n",
    "creates a heatmap of correlations between numeric features\n",
    "Example:\n",
    "``` python\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm') \n",
    "\n",
    "```\n",
    "\n",
    "* Box-Cox Transformation:\n",
    "Description: Used to stabilize variance and make data more normally distributed, especially for skewed data.\n",
    "Example: Applying the transformation to reduce skewness:\n",
    "``` python\n",
    " df['new_column'] = stats.boxcox(df['skewed_column'])[0]\n",
    "\n",
    " ```\n",
    "\n",
    "3. Loading the dataset using pandas\n",
    "* Loading the CSV file:\n",
    "Pandas is a widely-used Python library for data manipulation and analysis. One of its core functionalities is reading and writing data to various formats. When working with tabular data, the CSV (Comma-Separated Values) format is commonly encountered. To load a CSV file into a Pandas DataFrame, the read_csv() function is utilized.\n",
    "e.g.\n",
    "\n",
    "``` python\n",
    "import pandas as pd\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('path_to_file.csv')\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "```\n",
    "* Loading the excel file:\n",
    "Pandas, a popular Python library for data analysis, offers comprehensive tools to read and write data from diverse file formats. For Excel files, which are commonly used in business analytics and data reporting, Pandas provides the read_excel() function.\n",
    "e.g.\n",
    "\n",
    "``` python\n",
    "import pandas as pd\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel('path_to_file.xlsx')\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\t\n",
    "```\n",
    "\n",
    "4. Concept of DataFrame and Series\n",
    "Pandas Series: \n",
    "A Series in Pandas is one of the core data structures in the library. It represents a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.).\n",
    "e.g.\n",
    "```python\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Mike'],\n",
    "    'Age': [28, 22, 32],\n",
    "    'City': ['New York', 'Paris', 'London']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "Pandas DataFrame:\n",
    "A DataFrame in Pandas is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled axes (rows and columns). It can be thought of as a combination of multiple Pandas Series objects, where each column in the DataFrame is essentially a Series.\n",
    "e.g.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Mike'],\n",
    "    'Age': [28, 22, 32],\n",
    "    'City': ['New York', 'Paris', 'London']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5779ac8-38a9-4129-8ff2-ecd127d93a47",
   "metadata": {},
   "source": [
    "### 3. Discuss the process of handling missing values in a dataset. Provide Python code snippets demonstrating the\n",
    "### use of `fillna()` and `dropna()` functions in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bdf644-a09a-4c06-adb2-ae91f6d69b4a",
   "metadata": {},
   "source": [
    "Handling missing values: For any dataset data preprocessing if there are presence of missing values it can lead to inaccurate analyses or model predictions. There are different approaches for handling missing values based on the dataset based on the missing values scenarios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c38a69-e3e1-44ba-b4fa-af581fc19355",
   "metadata": {},
   "source": [
    "### Different approches\n",
    "#### Remove Missing Data:\n",
    "If the volume of missing data is minimal and if it is not affecting any changes in the model you can remove the rows or columns containing missing values.\n",
    "#### Filling Missing Data:\n",
    "The missing values can be replaced by meaningful data, such as the \n",
    "1. Mean\n",
    "2. Median\n",
    "3. Mode\n",
    "\n",
    "##### Other Methods\n",
    "\n",
    "1. Forward filling \n",
    "2. Backward filling\n",
    "3. Predictive modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5adf4-3e85-4c45-b387-9eaadd453a53",
   "metadata": {},
   "source": [
    "#### Using fillna() and dropna() in Pandas\n",
    "* Pandas provides two primary functions for handling missing data: fillna() and dropna().\n",
    "1. fillna()\n",
    "The fillna() function is used to replace missing values (NaN) with a specified value or a method(mean,mode, forward or backward filling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a2641b13-41d1-4e45-b7d8-32c4e3479a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original student Dataframe\n",
      "_________________________\n",
      "\n",
      "    Name   Age  Credits\n",
      "0     Jo   NaN      1.0\n",
      "1   Mark  30.0      NaN\n",
      "2    Nav  32.0      3.0\n",
      "3  Kiran   NaN      4.0\n",
      "4    Sam  24.0      5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Student DataFrame\n",
    "student_df = pd.DataFrame({\n",
    "    'Name': ['Jo', 'Mark', 'Nav', 'Kiran', 'Sam'],\n",
    "    'Age': [None, 30, 32, None, 24],\n",
    "    'Credits': [1, None, 3, 4, 5]\n",
    "})\n",
    "\n",
    "print(\"Original student Dataframe\")\n",
    "print(\"_________________________\\n\")\n",
    "print(student_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0c4945d8-8465-49ee-86e3-617b9c94817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Student Dataframe replacing missing values in column Age with Mean value of column\n",
      "___________________________________________________________________________\n",
      "\n",
      "    Name        Age  Credits\n",
      "0     Jo  28.666667      1.0\n",
      "1   Mark  30.000000      NaN\n",
      "2    Nav  32.000000      3.0\n",
      "3  Kiran  28.666667      4.0\n",
      "4    Sam  24.000000      5.0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in column 'Age' with the mean of the column\n",
    "student_df['Age'].fillna(student_df['Age'].mean(), inplace=True)\n",
    "\n",
    "print(\" Student Dataframe replacing missing values in column Age with Mean value of column\")\n",
    "print(\"___________________________________________________________________________\\n\")\n",
    "print(student_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "305c032d-0773-46a8-b626-05f8d48c4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Student Dataframe replacing missing values with Zero's\n",
      "___________________________________________________________________________\n",
      "\n",
      "    Name        Age  Credits\n",
      "0     Jo  28.666667      1.0\n",
      "1   Mark  30.000000      0.0\n",
      "2    Nav  32.000000      3.0\n",
      "3  Kiran  28.666667      4.0\n",
      "4    Sam  24.000000      5.0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in the entire DataFrame with 0\n",
    "student_df.fillna(0, inplace=True)\n",
    "\n",
    "print(\" Student Dataframe replacing missing values with Zero's\")\n",
    "print(\"___________________________________________________________________________\\n\")\n",
    "print(student_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8f6cf50c-c1fb-4eae-91a3-fa810793982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Marks\n",
      "0   1    NaN\n",
      "1   2   30.0\n",
      "2   3   32.0\n",
      "3   4    NaN\n",
      "4   5   24.0\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "marks_df = pd.DataFrame({\n",
    "    'Id': [1, 2, 3, 4, 5],\n",
    "    'Marks': [None, 30, 32, None, 24]\n",
    "})\n",
    "\n",
    "print(marks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cdb312c4-0c29-498d-9144-3cfd9fa285d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with Forward or Backward Filling:\n",
    "\n",
    "# Replace missing values with the preceding (forward fill) or following (backward fill) value.\n",
    "\n",
    "# Forward fill missing values\n",
    "marks_df.fillna(method='ffill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2c100567-0aff-46d2-805b-edb84570d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marks Dataframe after forward filling\n",
      "______________________________________\n",
      "\n",
      "   Id  Marks\n",
      "0   1    NaN\n",
      "1   2   30.0\n",
      "2   3   32.0\n",
      "3   4   32.0\n",
      "4   5   24.0\n"
     ]
    }
   ],
   "source": [
    "# Marks df after forward filling\n",
    "print(\"Marks Dataframe after forward filling\")\n",
    "print('______________________________________\\n')\n",
    "print(marks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5aee6b9d-64c0-4614-9fcf-e5ec9b25e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward fill missing values\n",
    "marks_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "da3e657c-63eb-48f6-82d7-390fd5159619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marks Dataframe after Backward filling\n",
      "______________________________________\n",
      "\n",
      "   Id  Marks\n",
      "0   1   30.0\n",
      "1   2   30.0\n",
      "2   3   32.0\n",
      "3   4   32.0\n",
      "4   5   24.0\n"
     ]
    }
   ],
   "source": [
    "# Marks df after Backward filling\n",
    "print(\"Marks Dataframe after Backward filling\")\n",
    "print('______________________________________\\n')\n",
    "print(marks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4044837b-4de4-4862-8118-5f9b64c60ff3",
   "metadata": {},
   "source": [
    "2. dropna()\n",
    "The dropna() function is used to remove rows or columns with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d3c61ad7-0051-47b9-9c3f-b0a88683cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed rows having at least a missing value\n",
      "______________________________________\n",
      "\n",
      "   A     B\n",
      "1  2  30.0\n",
      "2  3  32.0\n",
      "4  5  24.0\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [None, 30, 32, None, 24]\n",
    "})\n",
    "# Drop Rows with Missing Values:\n",
    "# Remove any rows containing at least one missing value.\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(\"Removed rows having at least a missing value\")\n",
    "print('______________________________________\\n')\n",
    "\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2df9a818-1c7c-4261-a316-c885747c2811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns having at least a missing value\n",
      "______________________________________\n",
      "\n",
      "   A\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n"
     ]
    }
   ],
   "source": [
    "# Drop Columns with Missing Values:\n",
    "# Remove any columns containing at least one missing value.\n",
    "\n",
    "# Drop columns with any missing values\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "print(\"Removed columns having at least a missing value\")\n",
    "print('______________________________________\\n')\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "291347d7-3b2b-47b3-97ce-66e0c157111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop columns if all values are missing\n",
      "_____________________\n",
      "\n",
      "   A     B\n",
      "0  1   NaN\n",
      "1  2  30.0\n",
      "2  3  32.0\n",
      "3  4   NaN\n",
      "4  5  24.0\n"
     ]
    }
   ],
   "source": [
    "# Drop Rows or Columns Only If All Values Are Missing:\n",
    "# Drop rows only if all values are missing\n",
    "df_cleaned = df.dropna(how='all')\n",
    "# Remove rows or columns only if all values are missing.\n",
    "\n",
    "# Drop columns only if all values are missing\n",
    "df_cleaned = df.dropna(axis=1, how='all')\n",
    "print(\"Drop columns if all values are missing\")\n",
    "print(\"_____________________\\n\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384d5b9-f091-47be-91ff-0535dbd5a74c",
   "metadata": {},
   "source": [
    "### 4. Write Python code to perform data type conversion for a given dataset. Include examples of converting continuous and categorical data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "56303555-8803-43b4-80a7-f9f3dd5ba2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "mart_df = pd.read_csv('bigmart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ef7cdf9e-0ed3-4a4d-8506-5ad97b1f0dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 5 rows\n",
    "mart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "32eab65e-5014-4eec-9cae-948f0e7abd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            8523 non-null   object \n",
      " 1   Item_Weight                7060 non-null   float64\n",
      " 2   Item_Fat_Content           8523 non-null   object \n",
      " 3   Item_Visibility            8523 non-null   float64\n",
      " 4   Item_Type                  8523 non-null   object \n",
      " 5   Item_MRP                   8523 non-null   float64\n",
      " 6   Outlet_Identifier          8523 non-null   object \n",
      " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
      " 8   Outlet_Size                6113 non-null   object \n",
      " 9   Outlet_Location_Type       8523 non-null   object \n",
      " 10  Outlet_Type                8523 non-null   object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Info function output for the dataset\n",
    "mart_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f59ae50c-b92c-4cb2-b386-399f4875212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all null values\n",
    "mart_df = mart_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e9ef1042-b082-4b3d-bb58-48f808b9edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df after removing null values\n",
      "______________________\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4650 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            4650 non-null   object \n",
      " 1   Item_Weight                4650 non-null   float64\n",
      " 2   Item_Fat_Content           4650 non-null   object \n",
      " 3   Item_Visibility            4650 non-null   float64\n",
      " 4   Item_Type                  4650 non-null   object \n",
      " 5   Item_MRP                   4650 non-null   float64\n",
      " 6   Outlet_Identifier          4650 non-null   object \n",
      " 7   Outlet_Establishment_Year  4650 non-null   int64  \n",
      " 8   Outlet_Size                4650 non-null   object \n",
      " 9   Outlet_Location_Type       4650 non-null   object \n",
      " 10  Outlet_Type                4650 non-null   object \n",
      " 11  Item_Outlet_Sales          4650 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 472.3+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Original df after removing null values\")\n",
    "print(\"______________________\\n\")\n",
    "mart_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0e4054ea-ba1b-46c7-934f-6efd53d6f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Continuous Data Type Conversion ---- #\n",
    "# Converting 'Age' (float) to int\n",
    "mart_df['Item_Weight'] = mart_df['Item_Weight'].astype(int)\n",
    "\n",
    "# Converting 'target' (int) to float\n",
    "mart_df['Outlet_Establishment_Year'] = mart_df['Outlet_Establishment_Year'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "090a665c-fa0d-48cc-8ee9-f52c7e8e49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After conversion of data type\n",
      "______________________\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4650 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            4650 non-null   object \n",
      " 1   Item_Weight                4650 non-null   int64  \n",
      " 2   Item_Fat_Content           4650 non-null   object \n",
      " 3   Item_Visibility            4650 non-null   float64\n",
      " 4   Item_Type                  4650 non-null   object \n",
      " 5   Item_MRP                   4650 non-null   float64\n",
      " 6   Outlet_Identifier          4650 non-null   object \n",
      " 7   Outlet_Establishment_Year  4650 non-null   float64\n",
      " 8   Outlet_Size                4650 non-null   object \n",
      " 9   Outlet_Location_Type       4650 non-null   object \n",
      " 10  Outlet_Type                4650 non-null   object \n",
      " 11  Item_Outlet_Sales          4650 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 472.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking info after converting\n",
    "print(\"After conversion of data type\")\n",
    "print(\"______________________\\n\")\n",
    "mart_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7329055d-b569-4781-b776-9189313797f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Medium', 'High', 'Small'], dtype=object)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values for Outlet_Size column\n",
    "mart_df['Outlet_Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "51046814-84ab-46a4-b1c4-4f9058589c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'Regular', 'low fat', 'reg', 'LF'], dtype=object)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values for Item_Fat_Content column\n",
    "mart_df['Item_Fat_Content'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1b0ab690-b39f-480b-9e2a-4e6927d9dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping correct values for Item_Fat_Content column which are with different naming\n",
    "mart_df['Item_Fat_Content'] = mart_df['Item_Fat_Content'].map({'low fat': 'Low Fat', 'reg': 'Regular','LF':'Low Fat',\n",
    "                                                              'Low Fat':'Low Fat', 'Regular':'Regular' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "742f5969-f59c-4ff7-b621-704bf56c4f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'Regular'], dtype=object)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values for Item_Fat_Content column after mapping with correct name\n",
    "mart_df['Item_Fat_Content'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90846bd9-a887-4877-9485-a45a0f9b2dfd",
   "metadata": {},
   "source": [
    "##### 2. Convert categorical 'Item_Fat_Content' and 'Outlet_Size' to numerical values (Label Encoding) ###\n",
    "##### Label encoding for 'Item_Fat_Content' and 'Outlet_Size' columns using map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6945b12c-c5d5-4160-a25b-8de23e9681af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mart_df['Item_Fat_Content_Code'] = mart_df['Item_Fat_Content'].map({'Low Fat': 0, 'Regular': 1})\n",
    "mart_df['Outlet_Size_Code'] = mart_df['Outlet_Size'].map({'Small': 0, 'Medium': 1,'High':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d3c1bc68-70e8-4334-ba9f-3726dae79000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mapping\n",
      "_____________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Fat_Content_Code</th>\n",
       "      <th>Outlet_Size_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FDP36</td>\n",
       "      <td>10</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>51.4008</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>556.6088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15            9          Low Fat         0.016047   \n",
       "1           DRC01            5          Regular         0.019278   \n",
       "2           FDN15           17          Low Fat         0.016760   \n",
       "4           NCD19            8          Low Fat         0.000000   \n",
       "5           FDP36           10          Regular         0.000000   \n",
       "\n",
       "      Item_Type  Item_MRP Outlet_Identifier  Outlet_Establishment_Year  \\\n",
       "0         Dairy  249.8092            OUT049                     1999.0   \n",
       "1   Soft Drinks   48.2692            OUT018                     2009.0   \n",
       "2          Meat  141.6180            OUT049                     1999.0   \n",
       "4     Household   53.8614            OUT013                     1987.0   \n",
       "5  Baking Goods   51.4008            OUT018                     2009.0   \n",
       "\n",
       "  Outlet_Size Outlet_Location_Type        Outlet_Type  Item_Outlet_Sales  \\\n",
       "0      Medium               Tier 1  Supermarket Type1          3735.1380   \n",
       "1      Medium               Tier 3  Supermarket Type2           443.4228   \n",
       "2      Medium               Tier 1  Supermarket Type1          2097.2700   \n",
       "4        High               Tier 3  Supermarket Type1           994.7052   \n",
       "5      Medium               Tier 3  Supermarket Type2           556.6088   \n",
       "\n",
       "   Item_Fat_Content_Code  Outlet_Size_Code  \n",
       "0                      0                 1  \n",
       "1                      1                 1  \n",
       "2                      0                 1  \n",
       "4                      0                 2  \n",
       "5                      1                 1  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"After mapping\")\n",
    "print(\"_____________\")\n",
    "mart_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae9439-9a9e-4984-822b-3120a0bdaaea",
   "metadata": {},
   "source": [
    "### 5. Implement a Python function to merge two datasets based on a single key column using Pandas. Provide a code example and explain the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "dc9615bd-82c4-4339-b5b2-e27bbd26c777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame (Inner Join):\n",
      "______________________________\n",
      "   student_id  course_id_x   semester_x grades_x  course_id_y   semester_y  \\\n",
      "0         101          301  2024 Spring        A          301  2024 Spring   \n",
      "1         102          302  2024 Spring        B          302  2024 Spring   \n",
      "2         103          301    2024 Fall       A+          301    2024 Fall   \n",
      "3         105          304  2024 Spring        C          304  2024 Spring   \n",
      "\n",
      "  grades_y  \n",
      "0       A-  \n",
      "1       B+  \n",
      "2        A  \n",
      "3       B-  \n",
      "\n",
      "Merged DataFrame (Outer Join):\n",
      "______________________________\n",
      "   student_id  course_id_x   semester_x grades_x  course_id_y   semester_y  \\\n",
      "0         101        301.0  2024 Spring        A          301  2024 Spring   \n",
      "1         102        302.0  2024 Spring        B          302  2024 Spring   \n",
      "2         103        301.0    2024 Fall       A+          301    2024 Fall   \n",
      "3         105        304.0  2024 Spring        C          304  2024 Spring   \n",
      "4         106          NaN          NaN      NaN          300  2024 Spring   \n",
      "\n",
      "  grades_y  \n",
      "0       A-  \n",
      "1       B+  \n",
      "2        A  \n",
      "3       B-  \n",
      "4        A  \n",
      "\n",
      "Merged DataFrame (Right Join):\n",
      "______________________________\n",
      "   student_id  course_id_x   semester_x grades_x  course_id_y   semester_y  \\\n",
      "0         101        301.0  2024 Spring        A          301  2024 Spring   \n",
      "1         102        302.0  2024 Spring        B          302  2024 Spring   \n",
      "2         103        301.0    2024 Fall       A+          301    2024 Fall   \n",
      "3         105        304.0  2024 Spring        C          304  2024 Spring   \n",
      "4         106          NaN          NaN      NaN          300  2024 Spring   \n",
      "\n",
      "  grades_y  \n",
      "0       A-  \n",
      "1       B+  \n",
      "2        A  \n",
      "3       B-  \n",
      "4        A  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to merge two datasets based on a key column\n",
    "def merge_datasets(df1, df2, key_column, how='inner'):\n",
    "    \"\"\"\n",
    "    Merge two dataframes on a specified key column.\n",
    "\n",
    "    :param df1: First dataframe\n",
    "    :param df2: Second dataframe\n",
    "    :param key_column: The column name on which to merge\n",
    "    :param how: Type of merge - 'left', 'right', 'outer', 'inner' (default is 'inner')\n",
    "    :return: Merged dataframe\n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(df1, df2, on=key_column, how=how)\n",
    "    return merged_df\n",
    "\n",
    "# Example dataframes with Enrollments and New grades data\n",
    "df_enrollments = pd.DataFrame({\n",
    "    'student_id':[101,102,103,105],\n",
    "    'course_id':[301,302,301,304],\n",
    "    'semester':['2024 Spring', '2024 Spring', '2024 Fall','2024 Spring'],\n",
    "    'grades': ['A','B','A+','C']\n",
    "})\n",
    "\n",
    "df_new_grades = pd.DataFrame({\n",
    "    'student_id':[101,102,103,105,106],\n",
    "    'course_id':[301,302, 301,304,300],\n",
    "    'semester':['2024 Spring', '2024 Spring', '2024 Fall','2024 Spring','2024 Spring'],\n",
    "    'grades': ['A-','B+','A','B-', 'A']\n",
    "} )\n",
    "\n",
    "\n",
    "# Merge the datasets on the 'student_id' column\n",
    "merged_df = merge_datasets(df_enrollments, df_new_grades, 'student_id', how='inner')\n",
    "\n",
    "print(\"Merged DataFrame (Inner Join):\")\n",
    "print(\"______________________________\")\n",
    "print(merged_df)\n",
    "\n",
    "# Try different types of merge (e.g., outer join)\n",
    "outer_merged_df = merge_datasets(df_enrollments, df_new_grades, 'student_id', how='outer')\n",
    "\n",
    "print(\"\\nMerged DataFrame (Outer Join):\")\n",
    "print(\"______________________________\")\n",
    "print(outer_merged_df)\n",
    "\n",
    "# Try different types of merge (e.g., right join)\n",
    "right_merged_df = merge_datasets(df_enrollments, df_new_grades, 'student_id', how='right')\n",
    "\n",
    "print(\"\\nMerged DataFrame (Right Join):\")\n",
    "print(\"______________________________\")\n",
    "print(right_merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d204da9-fab4-4f2b-ac90-786a77afb92a",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Function Definition:\n",
    "\n",
    "The function merge_datasets(df1, df2, key_column,how='inner') takes two DataFrames (df1, df2) and the name of the key column (key_column) as input.\n",
    "It merges the two DataFrames using pd.merge(df1, df2, on=key_column, how='join type'), which merges on the specified key column.\n",
    "Sample DataFrames:\n",
    "\n",
    "* df_enrollments contains student information (student ID, courseId, Semester and Grades).\n",
    "* df_new_grades contains student information (student ID, courseId, Semester and Grades).\n",
    "Both datasets share the student_id column, which is used as the key for merging.\n",
    "Merging:\n",
    "\n",
    "The pd.merge() function merges the two DataFrames based on the student_id column, keeping only the rows where student_id is present in both DataFrames (this is the default \"inner join\" behavior).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b95e5f-d08a-4f4d-b59a-93b74687ca07",
   "metadata": {},
   "source": [
    "### 6. How would you use the `groupby()` functionality in Pandas to perform aggregate functions like sum, average, max, and min on a dataset? Provide Python code demonstrating each aggregate function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32187596-71ee-43eb-a519-1c640893e57c",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "In general, grouping data in Pandas works as follows:\n",
    "\n",
    "\n",
    "```python\n",
    "df.groupby(by=grouping_columns)[columns_to_show].function()\n",
    "```\n",
    "\n",
    "1. First, the `groupby` method divides the `grouping_columns` by their values. They become a new index in the resulting dataframe.\n",
    "2. Then, columns of interest are selected (`columns_to_show`). If `columns_to_show` is not included, all non groupby clauses will be included.\n",
    "3. Finally, one or several functions are applied to the obtained groups per selected columns.\n",
    "\n",
    "Here is an example where we group the data according to the values of the `Churn` variable and display statistics of three columns in each group:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb71e5a-d033-4418-af33-7443d6b033ec",
   "metadata": {},
   "source": [
    "#### Loading MentalHealth dataset MentalHealthSurvey.csv\n",
    "#### Kaggle https://www.kaggle.com/datasets/abdullahashfaqvirk/student-mental-health-survey?resource=download&select=MentalHealthSurvey.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6e809b96-7176-4efc-889c-302077d3fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "health_df = pd.read_csv(\"MentalHealthSurvey.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e51cc1fa-ec83-497f-a804-a129ea7d50aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>university</th>\n",
       "      <th>degree_level</th>\n",
       "      <th>degree_major</th>\n",
       "      <th>academic_year</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>residential_status</th>\n",
       "      <th>campus_discrimination</th>\n",
       "      <th>sports_engagement</th>\n",
       "      <th>...</th>\n",
       "      <th>study_satisfaction</th>\n",
       "      <th>academic_workload</th>\n",
       "      <th>academic_pressure</th>\n",
       "      <th>financial_concerns</th>\n",
       "      <th>social_relationships</th>\n",
       "      <th>depression</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>isolation</th>\n",
       "      <th>future_insecurity</th>\n",
       "      <th>stress_relief_activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>PU</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>2nd year</td>\n",
       "      <td>3.0-3.5</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>No</td>\n",
       "      <td>No Sports</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Religious Activities, Social Connections, Onli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>UET</td>\n",
       "      <td>Postgraduate</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>3rd year</td>\n",
       "      <td>3.0-3.5</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>No</td>\n",
       "      <td>1-3 times</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Online Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>FAST</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>3rd year</td>\n",
       "      <td>2.5-3.0</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>No</td>\n",
       "      <td>1-3 times</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Religious Activities, Sports and Fitness, Onli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>UET</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>3rd year</td>\n",
       "      <td>2.5-3.0</td>\n",
       "      <td>On-Campus</td>\n",
       "      <td>No</td>\n",
       "      <td>No Sports</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Online Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>UET</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>3rd year</td>\n",
       "      <td>3.0-3.5</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No Sports</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Online Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age university   degree_level      degree_major academic_year  \\\n",
       "0    Male   20         PU  Undergraduate      Data Science      2nd year   \n",
       "1    Male   20        UET   Postgraduate  Computer Science      3rd year   \n",
       "2    Male   20       FAST  Undergraduate  Computer Science      3rd year   \n",
       "3    Male   20        UET  Undergraduate  Computer Science      3rd year   \n",
       "4  Female   20        UET  Undergraduate  Computer Science      3rd year   \n",
       "\n",
       "      cgpa residential_status campus_discrimination sports_engagement  ...  \\\n",
       "0  3.0-3.5         Off-Campus                    No         No Sports  ...   \n",
       "1  3.0-3.5         Off-Campus                    No         1-3 times  ...   \n",
       "2  2.5-3.0         Off-Campus                    No         1-3 times  ...   \n",
       "3  2.5-3.0          On-Campus                    No         No Sports  ...   \n",
       "4  3.0-3.5         Off-Campus                   Yes         No Sports  ...   \n",
       "\n",
       "  study_satisfaction  academic_workload   academic_pressure  \\\n",
       "0                  5                   4                  5   \n",
       "1                  5                   4                  4   \n",
       "2                  5                   5                  5   \n",
       "3                  3                   5                  4   \n",
       "4                  3                   5                  5   \n",
       "\n",
       "   financial_concerns  social_relationships  depression  anxiety  isolation  \\\n",
       "0                   4                     3           2        1          1   \n",
       "1                   1                     3           3        3          3   \n",
       "2                   3                     4           2        3          3   \n",
       "3                   4                     1           5        5          5   \n",
       "4                   2                     3           5        5          4   \n",
       "\n",
       "   future_insecurity                           stress_relief_activities  \n",
       "0                  2  Religious Activities, Social Connections, Onli...  \n",
       "1                  4                               Online Entertainment  \n",
       "2                  1  Religious Activities, Sports and Fitness, Onli...  \n",
       "3                  3                               Online Entertainment  \n",
       "4                  4                               Online Entertainment  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top 5 rows\n",
    "health_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0b62d70e-97dc-4145-baaf-6c01fb38cd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   gender                    87 non-null     object\n",
      " 1   age                       87 non-null     int64 \n",
      " 2   university                87 non-null     object\n",
      " 3   degree_level              87 non-null     object\n",
      " 4   degree_major              87 non-null     object\n",
      " 5   academic_year             87 non-null     object\n",
      " 6   cgpa                      87 non-null     object\n",
      " 7   residential_status        87 non-null     object\n",
      " 8   campus_discrimination     87 non-null     object\n",
      " 9   sports_engagement         87 non-null     object\n",
      " 10  average_sleep             87 non-null     object\n",
      " 11  study_satisfaction        87 non-null     int64 \n",
      " 12  academic_workload         87 non-null     int64 \n",
      " 13  academic_pressure         87 non-null     int64 \n",
      " 14  financial_concerns        87 non-null     int64 \n",
      " 15  social_relationships      87 non-null     int64 \n",
      " 16  depression                87 non-null     int64 \n",
      " 17  anxiety                   87 non-null     int64 \n",
      " 18  isolation                 87 non-null     int64 \n",
      " 19  future_insecurity         87 non-null     int64 \n",
      " 20  stress_relief_activities  87 non-null     object\n",
      "dtypes: int64(10), object(11)\n",
      "memory usage: 14.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# print info\n",
    "health_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7eb699b5-c74c-4535-bdb8-933743051be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Science', 'Computer Science', 'Software Engineering',\n",
       "       'Information Technology'], dtype=object)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting unique values for degree_major column\n",
    "health_df['degree_major'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f4c2e01d-9541-4575-89f0-4889431f7399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_major</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Computer Science</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Science</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Technology</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Engineering</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Off-Campus</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count unique         top freq\n",
       "degree_major                                        \n",
       "Computer Science          34      2  Off-Campus   23\n",
       "Data Science              41      2  Off-Campus   31\n",
       "Information Technology     9      2  Off-Campus    8\n",
       "Software Engineering       3      1  Off-Campus    3"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display statistics of residential_status columns in each degree_major group:\n",
    "health_df.groupby(['degree_major'])['residential_status'].describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995ea0f-c8d1-4dca-89d7-bb2c53877280",
   "metadata": {},
   "source": [
    "By passing a list of functions to `agg()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202869e-2ed8-4975-9ba9-6dc23b1971ad",
   "metadata": {},
   "source": [
    "Below code snippet uses the groupby() method  to group the data in health_df by the \"academic_year\" column and then applies aggregate functions (mean, std, min, and max) to the \"study_satisfaction\" column. This operation helps summarize the satisfaction levels for each academic year by computing key statistical metrics.\n",
    "\n",
    "With agg(), you can apply multiple aggregate functions on different columns at once. In this example, we calculated the  std,mean, max, and min for the study_satisfaction column using academic_year as the group by ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "079c4dea-0a82-4cb8-8c64-4e27cfbe71a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>academic_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1st year</th>\n",
       "      <td>4.058824</td>\n",
       "      <td>1.179141</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd year</th>\n",
       "      <td>3.933333</td>\n",
       "      <td>1.032796</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd year</th>\n",
       "      <td>3.821429</td>\n",
       "      <td>0.772374</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th year</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.316561</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean       std  min  max\n",
       "academic_year                              \n",
       "1st year       4.058824  1.179141    1    5\n",
       "2nd year       3.933333  1.032796    2    5\n",
       "3rd year       3.821429  0.772374    3    5\n",
       "4th year       3.800000  1.316561    1    5"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_df.groupby([\"academic_year\"])[\"study_satisfaction\"].agg(['mean', 'std', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007b154-c15e-4d65-a864-1337f870f101",
   "metadata": {},
   "source": [
    "Sum (sum):\n",
    "Calculates the total salary and total age for each department.\n",
    "\n",
    "Mean (mean):\n",
    "Finds the average salary and average age for each department.\n",
    "\n",
    "Max (max):\n",
    "Determines the maximum salary and age in each department.\n",
    "\n",
    "Min (min):\n",
    "Finds the minimum salary and age in each department.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "03779024-1eab-4386-84cf-7275ac43a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sum of study_satisfaction and social_relationships by degree_level:\n",
      "____________\n",
      "               study_satisfaction  social_relationships\n",
      "degree_level                                           \n",
      "Postgraduate                    9                     5\n",
      "Undergraduate                 333                   237\n"
     ]
    }
   ],
   "source": [
    "# Group by 'degree_level' and calculate the sum of 'study_satisfaction' and 'social_relationships'\n",
    "grouped_sum = health_df.groupby(['degree_level'])[['study_satisfaction','social_relationships']].sum()\n",
    "\n",
    "print(\"\\nSum of study_satisfaction and social_relationships by degree_level:\")\n",
    "print(\"____________\")\n",
    "print(grouped_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d1de3bb6-5cbc-49e1-9180-596e1b9827b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average of depression by residential_status:\n",
      "____________\n",
      "residential_status\n",
      "Off-Campus    3.230769\n",
      "On-Campus     3.181818\n",
      "Name: depression, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'residential_status' and calculate the average of 'depression' \n",
    "grouped_avg = health_df.groupby(['residential_status'])['depression'].mean()\n",
    "\n",
    "print(\"\\n Average of depression by residential_status:\")\n",
    "print(\"____________\")\n",
    "print(grouped_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "36f4fe7c-0fac-413f-94d1-8cd088620e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Max of social_relationships by academic_year:\n",
      "____________\n",
      "academic_year\n",
      "1st year    5\n",
      "2nd year    5\n",
      "3rd year    5\n",
      "4th year    4\n",
      "Name: social_relationships, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'academic_year' and calculate the max of 'social_relationships' \n",
    "grouped_max = health_df.groupby(['academic_year'])['social_relationships'].max()\n",
    "\n",
    "print(\"\\n Max of social_relationships by academic_year:\")\n",
    "print(\"____________\")\n",
    "print(grouped_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c371db17-c7b4-4762-acc9-6d4c2b325cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Min of financial_concerns by academic_year:\n",
      "____________\n",
      "academic_year\n",
      "1st year    1\n",
      "2nd year    1\n",
      "3rd year    1\n",
      "4th year    1\n",
      "Name: financial_concerns, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'academic_year' and calculate the min of 'financial_concerns' \n",
    "grouped_min = health_df.groupby(['academic_year'])['financial_concerns'].min()\n",
    "\n",
    "print(\"\\n Min of financial_concerns by academic_year:\")\n",
    "print(\"____________\")\n",
    "print(grouped_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "6371f30c-5e4d-4aa1-ad11-8ee86b4e2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Midterm_Exam.ipynb to webpdf\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 892692 bytes to Midterm_Exam.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to webpdf --allow-chromium-download Midterm_Exam.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d38648-661b-4786-9bbd-c83cbbfb0ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
